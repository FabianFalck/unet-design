{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a064a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Latex preamble\n",
    "# matplotlib.rc('text', usetex=True)\n",
    "# matplotlib.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]\n",
    "\n",
    "import math \n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cpu\")#torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c305cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Approximator(nn.Module):\n",
    "    \n",
    "    def __init__(self, nlatent=20, ndim=2):\n",
    "        super(Approximator, self).__init__()\n",
    "        \n",
    "        self.n_repeats = 20\n",
    "        self.h  = 1/self.n_repeats\n",
    "        \n",
    "        self.ndim = ndim\n",
    "        self.nlatent = nlatent\n",
    "        \n",
    "        self.f0 = lambda x : x\n",
    "        \n",
    "        \n",
    "        self.regressor = nn.Sequential(nn.Linear(self.ndim, self.nlatent),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Linear(self.nlatent, self.nlatent),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Linear(self.nlatent, self.ndim)) \n",
    "    \n",
    "    def r_n_repeats(self, n):\n",
    "        \n",
    "        self.n_repeats = n\n",
    "        self.h  = 1/self.n_repeats\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.f0(x)\n",
    "        \n",
    "        for _ in range(self.n_repeats):\n",
    "            \n",
    "            flux = self.regressor(x)\n",
    "\n",
    "            x = x + self.h*flux\n",
    "            \n",
    "        output = x\n",
    "        return output\n",
    "\n",
    "    \n",
    "def project_con(model, gamma = 0.9):\n",
    "    \n",
    "    if gamma == np.inf:\n",
    "        \n",
    "        return\n",
    "    \n",
    "    W_norm, hW_norm, W_dist = find_nn_norm(model)\n",
    "    \n",
    "    if hW_norm < gamma:\n",
    "        \n",
    "        return\n",
    "        \n",
    "    param_dict = model.state_dict()\n",
    "\n",
    "    i = 0 \n",
    "\n",
    "    for p in param_dict.keys():\n",
    "\n",
    "        if 'weight' in p:\n",
    "            \n",
    "            c = np.power(W_norm*model.h,W_dist[i])\n",
    "            cg = np.power(gamma,W_dist[i])\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "            W = param_dict[p]\n",
    "\n",
    "            param_dict[p] = cg*W/c\n",
    "\n",
    "    model.load_state_dict(param_dict)\n",
    "    \n",
    "    return\n",
    "\n",
    "def find_nn_norm(f_nn):\n",
    "\n",
    "    param_dict = f_nn.state_dict()\n",
    "\n",
    "    W_norm = 1.0\n",
    "    \n",
    "    w_dist = []\n",
    "\n",
    "    for p in param_dict.keys():\n",
    "\n",
    "        if 'weight' in p:\n",
    "\n",
    "            W = param_dict[p]\n",
    "\n",
    "            pnorm = torch.norm(W)\n",
    "            \n",
    "            w_dist.append(np.log(pnorm))\n",
    "\n",
    "            W_norm = W_norm*pnorm\n",
    "            \n",
    "    w_dist = w_dist/np.log(W_norm.detach().numpy())\n",
    "    \n",
    "    return W_norm, W_norm*f_nn.h, w_dist\n",
    "\n",
    "\n",
    "def train_func_approx(model,a_func,\n",
    "                      LR = 1e-2,\n",
    "                      MAX_EPOCH = 20,\n",
    "                      BATCH_SIZE = 512,\n",
    "                      range_lr = [0.,1.],\n",
    "                      gamma = 0.9):\n",
    "\n",
    "    X = np.random.rand(10**5,model.ndim)*(range_lr[1]-range_lr[0])+range_lr[0]\n",
    "    y = a_func(X)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = map(torch.tensor, \n",
    "                                         train_test_split(X, y, \n",
    "                                                          test_size=0.2))\n",
    "\n",
    "    train_dataloader = DataLoader(TensorDataset(X_train.unsqueeze(1), \n",
    "                                                y_train.unsqueeze(1)), \n",
    "                                  batch_size=BATCH_SIZE,\n",
    "                                  pin_memory=True, shuffle=True)\n",
    "\n",
    "    val_dataloader = DataLoader(TensorDataset(X_val.unsqueeze(1), \n",
    "                                              y_val.unsqueeze(1)), \n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                pin_memory=True, shuffle=True)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.MSELoss(reduction=\"mean\")\n",
    "    \n",
    "    project_con(model,gamma = gamma)\n",
    "    \n",
    " \n",
    "    train_loss_list = list()\n",
    "    val_loss_list = list()\n",
    "    for epoch in range(MAX_EPOCH):\n",
    "        print(\"epoch %d / %d\" % (epoch+1, MAX_EPOCH))\n",
    "        model.train()\n",
    "        \n",
    "        temp_loss_list = list()\n",
    "        for X_train, y_train in train_dataloader:\n",
    "            X_train = X_train.type(torch.float32).to(device)\n",
    "            y_train = y_train.type(torch.float32).to(device)\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            score = model(X_train)\n",
    "            \n",
    "            loss = criterion(input=score, target=y_train)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            temp_loss_list.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        # project constraint here (right now every epoch)\n",
    "        project_con(model,gamma = gamma)\n",
    "        \n",
    "        temp_loss_list = list()\n",
    "        for X_train, y_train in train_dataloader:\n",
    "            X_train = X_train.type(torch.float32).to(device)\n",
    "            y_train = y_train.type(torch.float32).to(device)\n",
    "\n",
    "            score = model(X_train)\n",
    "            loss = criterion(input=score, target=y_train)\n",
    "\n",
    "            temp_loss_list.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        train_loss_list.append(np.average(temp_loss_list))\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "\n",
    "        temp_loss_list = list()\n",
    "        for X_val, y_val in val_dataloader:\n",
    "            X_val = X_val.type(torch.float32).to(device)\n",
    "            y_val = y_val.type(torch.float32).to(device)\n",
    "\n",
    "            score = model(X_val)\n",
    "            loss = criterion(input=score, target=y_val)\n",
    "\n",
    "            temp_loss_list.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        val_loss_list.append(np.average(temp_loss_list))\n",
    "        \n",
    "        W, hW, W_dist = find_nn_norm(model)\n",
    "\n",
    "        print(\"\\ttrain loss: %.5f\" % train_loss_list[-1])\n",
    "        print(\"\\tval loss: %.5f\" % val_loss_list[-1])\n",
    "        print(\"\\tflux norm h: %.5f\" % hW)\n",
    "        print(\"\\tflux distribution:\", W_dist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6216f167",
   "metadata": {},
   "source": [
    "$x^2$ example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8921575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_x2 = lambda x : x**2\n",
    "\n",
    "f_nn_x2 = Approximator(nlatent=20, ndim=2).to(device)\n",
    "\n",
    "# doesn't do anything\n",
    "# f_nn_x2.nlatent = 20\n",
    "# f_nn_x2.ndim = 2\n",
    "\n",
    "f_nn_x2.f0 = lambda x : x\n",
    "f_nn_x2.r_n_repeats(100)  # set number of repeats\n",
    "\n",
    "\n",
    "\n",
    "print('discretisation info : ')\n",
    "print('\\nn repeats : %i' % f_nn_x2.n_repeats, \n",
    "      '\\nh         : %4f' % f_nn_x2.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514aa66b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('training f_nn: \\n')\n",
    "\n",
    "train_func_approx(f_nn_x2,f_x2,\n",
    "                  range_lr = [-1.,1.],\n",
    "                  MAX_EPOCH = 10,\n",
    "                  LR = 1e-3, \n",
    "                  gamma = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f8bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_grid,f_x2(xx_grid)[:,0], c = 'black')\n",
    "plt.plot(x_grid,f_nn_x2(xx_grid).detach().numpy()[:,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb2067fb",
   "metadata": {},
   "source": [
    "Example 1: $g = x^3, f_0 = x$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f71ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_x3 = lambda x : x**3\n",
    "\n",
    "f_nn_x3 = Approximator().to(device)\n",
    "\n",
    "f_nn_x3.nlatent = 20\n",
    "f_nn_x3.ndim = 2\n",
    "\n",
    "x_grid = torch.reshape(torch.linspace(-1,1,50),[50,1])\n",
    "xx_grid = torch.cat([x_grid for _ in range(f_nn_x3.ndim)],1)\n",
    "\n",
    "f_nn_x3.f0 = lambda x : x\n",
    "f_nn_x3.r_n_repeats(100)  # number of repeats of ResNet block\n",
    "\n",
    "print('discretisation info : ')\n",
    "print('\\nn repeats : %i' % f_nn_x3.n_repeats, \n",
    "      '\\nh         : %4f' % f_nn_x3.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac534731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('training f_nn: \\n')\n",
    "\n",
    "train_func_approx(f_nn_x3,f_x3,\n",
    "                  range_lr = [-1.,1.],\n",
    "                  MAX_EPOCH = 10,\n",
    "                  LR = 1e-3, \n",
    "                  gamma = 0.95)\n",
    "print(\"Training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d814d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib.rc('text', usetex=True)\n",
    "# matplotlib.rcParams['text.latex.preamble'] = [r'\\boldmath', r'\\amsmath']\n",
    "\n",
    "def plot_precond_func_approx(x, y_f, y_f_nn, y_f0, file_name, precon_legend='$R^{\\mathrm{pre}}(v)$ (preconditioner)'): \n",
    "    # compute error as l1 distance\n",
    "    error = np.abs(y_f - y_f_nn) \n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.axhline(y=0., color='black', linestyle='--', linewidth=.5)\n",
    "    plt.plot(x, y_f, c = 'black', label = r'$w(v) = v^2$ (ground-truth)')\n",
    "    plt.plot(x, y_f_nn, c = 'blue', label = r'$R(v)$ (approximation)')   # TODO fix \\boldsymbol{ for theta\n",
    "    plt.plot(x, y_f0, '-.', c = 'green', label = r'' + precon_legend)\n",
    "    # plt.plot(x, error, '--', c = 'red', linewidth=1, label = r'$|y - f_{\\theta}|$ ($L^1$-error)')  # TODO fix \\boldsymbol{ for theta\n",
    "    # show legend\n",
    "    plt.legend(loc='lower right', fontsize=15)\n",
    "    plt.xlim([-1,1])\n",
    "    plt.ylim([-1,1])\n",
    "    # set x ticks at -1 and 1\n",
    "    plt.xticks([-1,0,1])\n",
    "    # set y ticks at -1 and 1\n",
    "    plt.yticks([-1,0,1])\n",
    "\n",
    "    plt.xlabel(r'$v$', fontsize=15)\n",
    "    plt.ylabel(r'$w$', fontsize=15)\n",
    "\n",
    "    # plt.plot(x_grid,f_x3(xx_grid)[:,0], c = 'black', label = '$f(x)$')\n",
    "    # plt.plot(x_grid,f_nn_x3(xx_grid).detach().numpy()[:,0], c = 'blue', label = '$f_{\\boldsymbol{\\theta}}$')\n",
    "    # plt.\n",
    "    # x title in latex format\n",
    "    # plt.x_title('$\\mathbb{X}$')\n",
    "    # plt.xtitle('$g(\\mathbb{X})$')   # TODO in different colors\n",
    "\n",
    "    # save pdf with high resolution\n",
    "    plt.savefig('Figs_output/{}.pdf'.format(file_name), bbox_inches='tight', dpi=1000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac275996",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_grid\n",
    "y_f = f_x3(xx_grid)[:,0]\n",
    "y_f_nn = f_nn_x3(xx_grid).detach().numpy()[:,0]\n",
    "y_f0 = f_nn_x3.f0(x_grid).detach().numpy()[:,0]\n",
    "file_name = 'g_x^3_f0_x'\n",
    "\n",
    "plot_precond_func_approx(x=x, y_f=y_f, y_f_nn=y_f_nn, y_f0=y_f0, file_name=file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "541ca731",
   "metadata": {},
   "source": [
    "Example 2: $g = x^3, f_0 = \\vert x \\vert$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa98045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_x3 = lambda x : x**3\n",
    "\n",
    "f_nn_x3 = Approximator().to(device)\n",
    "\n",
    "f_nn_x3.nlatent = 20\n",
    "f_nn_x3.ndim = 2\n",
    "\n",
    "x_grid = torch.reshape(torch.linspace(-1,1,50),[50,1])\n",
    "xx_grid = torch.cat([x_grid for _ in range(f_nn_x3.ndim)],1)\n",
    "\n",
    "f_nn_x3.f0 = lambda x : np.abs(x)\n",
    "f_nn_x3.r_n_repeats(100)  # number of repeats of ResNet block\n",
    "\n",
    "print('discretisation info : ')\n",
    "print('\\nn repeats : %i' % f_nn_x3.n_repeats, \n",
    "      '\\nh         : %4f' % f_nn_x3.h)\n",
    "\n",
    "print('training f_nn: \\n')\n",
    "\n",
    "train_func_approx(f_nn_x3,f_x3,\n",
    "                  range_lr = [-1.,1.],\n",
    "                  MAX_EPOCH = 10,\n",
    "                  LR = 1e-3, \n",
    "                  gamma = 0.95)\n",
    "print(\"Training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc4671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_grid\n",
    "y_f = f_x3(xx_grid)[:,0]\n",
    "y_f_nn = f_nn_x3(xx_grid).detach().numpy()[:,0]\n",
    "y_f0 = f_nn_x3.f0(x_grid).detach().numpy()[:,0]\n",
    "file_name = 'g_x^3_f0_abs(x)'\n",
    "\n",
    "plot_precond_func_approx(x=x, y_f=y_f, y_f_nn=y_f_nn, y_f0=y_f0, file_name=file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "612fa660",
   "metadata": {},
   "source": [
    "Example 3: $g = x^2, f_0 = x$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d20fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_x3 = lambda x : x**2\n",
    "\n",
    "f_nn_x3 = Approximator().to(device)\n",
    "\n",
    "f_nn_x3.nlatent = 20\n",
    "f_nn_x3.ndim = 2\n",
    "\n",
    "x_grid = torch.reshape(torch.linspace(-1,1,50),[50,1])\n",
    "xx_grid = torch.cat([x_grid for _ in range(f_nn_x3.ndim)],1)\n",
    "\n",
    "f_nn_x3.f0 = lambda x : x\n",
    "f_nn_x3.r_n_repeats(100)  # number of repeats of ResNet block\n",
    "\n",
    "print('discretisation info : ')\n",
    "print('\\nn repeats : %i' % f_nn_x3.n_repeats, \n",
    "      '\\nh         : %4f' % f_nn_x3.h)\n",
    "\n",
    "print('training f_nn: \\n')\n",
    "\n",
    "train_func_approx(f_nn_x3,f_x3,\n",
    "                  range_lr = [-1.,1.],\n",
    "                  MAX_EPOCH = 10,\n",
    "                  LR = 1e-3, \n",
    "                  gamma = 0.95)\n",
    "print(\"Training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64261cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_grid\n",
    "y_f = f_x3(xx_grid)[:,0]\n",
    "y_f_nn = f_nn_x3(xx_grid).detach().numpy()[:,0]\n",
    "y_f0 = f_nn_x3.f0(x_grid).detach().numpy()[:,0]\n",
    "file_name = 'g_x^2_f0_x'\n",
    "\n",
    "plot_precond_func_approx(x=x, y_f=y_f, y_f_nn=y_f_nn, y_f0=y_f0, file_name=file_name, precon_legend=\"$R^{\\mathrm{pre}}(v) = v$ (preconditioner)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a71ed279",
   "metadata": {},
   "source": [
    "Example 4: $g = x^2, f_0 = \\vert x \\vert$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32707c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_x3 = lambda x : x**2\n",
    "\n",
    "f_nn_x3 = Approximator().to(device)\n",
    "\n",
    "f_nn_x3.nlatent = 20\n",
    "f_nn_x3.ndim = 2\n",
    "\n",
    "x_grid = torch.reshape(torch.linspace(-1,1,50),[50,1])\n",
    "xx_grid = torch.cat([x_grid for _ in range(f_nn_x3.ndim)],1)\n",
    "\n",
    "f_nn_x3.f0 = lambda x : np.abs(x)\n",
    "f_nn_x3.r_n_repeats(100)  # number of repeats of ResNet block\n",
    "\n",
    "print('discretisation info : ')\n",
    "print('\\nn repeats : %i' % f_nn_x3.n_repeats, \n",
    "      '\\nh         : %4f' % f_nn_x3.h)\n",
    "\n",
    "print('training f_nn: \\n')\n",
    "\n",
    "train_func_approx(f_nn_x3,f_x3,\n",
    "                  range_lr = [-1.,1.],\n",
    "                  MAX_EPOCH = 10,\n",
    "                  LR = 1e-3, \n",
    "                  gamma = 0.95)\n",
    "print(\"Training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dbe9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_grid\n",
    "y_f = f_x3(xx_grid)[:,0]\n",
    "y_f_nn = f_nn_x3(xx_grid).detach().numpy()[:,0]\n",
    "y_f0 = f_nn_x3.f0(x_grid).detach().numpy()[:,0]\n",
    "file_name = 'g_x^2_f0_abs(x)'\n",
    "\n",
    "plot_precond_func_approx(x=x, y_f=y_f, y_f_nn=y_f_nn, y_f0=y_f0, file_name=file_name, precon_legend=\"$R^{\\mathrm{pre}}(v) = \\mid v \\mid$ (preconditioner)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98f6e51f",
   "metadata": {},
   "source": [
    "$x^2$ example with $|x|$ preconditioning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9381b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_x2 = lambda x : x**2\n",
    "\n",
    "f_nn_x2 = Approximator().to(device)\n",
    "\n",
    "f_nn_x2.nlatent = 20\n",
    "f_nn_x2.ndim = 2\n",
    "\n",
    "f_nn_x2.f0 = lambda x : np.abs(x)\n",
    "f_nn_x2.r_n_repeats(100)\n",
    "\n",
    "print('discretisation info : ')\n",
    "print('\\nn repeats : %i' % f_nn_x3.n_repeats, \n",
    "      '\\nh         : %4f' % f_nn_x3.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5eb309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('training f_nn: \\n')\n",
    "\n",
    "train_func_approx(f_nn_x2,f_x2,\n",
    "                  range_lr = [-1.,1.],\n",
    "                  MAX_EPOCH = 10,\n",
    "                  LR = 1e-3, \n",
    "                  gamma = 0.95)\n",
    "print(\"Training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_grid,f_x2(xx_grid)[:,0], c = 'black')\n",
    "plt.plot(x_grid,f_nn_x2(xx_grid).detach().numpy()[:,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b07ca061",
   "metadata": {},
   "source": [
    "$x^3$ example with $|x|$ preconditioning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebda11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_x3 = lambda x : x**3\n",
    "\n",
    "f_nn_x3 = Approximator().to(device)\n",
    "\n",
    "f_nn_x3.nlatent = 20\n",
    "f_nn_x3.ndim = 2\n",
    "\n",
    "f_nn_x3.f0 = lambda x : np.abs(x)\n",
    "f_nn_x3.r_n_repeats(100)\n",
    "\n",
    "print('discretisation info : ')\n",
    "print('\\nn repeats : %i' % f_nn_x3.n_repeats, \n",
    "      '\\nh         : %4f' % f_nn_x3.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d02181",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training f_nn: \\n')\n",
    "\n",
    "train_func_approx(f_nn_x3,f_x3,\n",
    "                  range_lr = [-1.,1.],\n",
    "                  MAX_EPOCH = 10,\n",
    "                  LR = 1e-3, \n",
    "                  gamma = 0.95)\n",
    "print(\"Training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f073cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_grid,f_x3(xx_grid)[:,0], c = 'black')\n",
    "plt.plot(x_grid,f_nn_x3(xx_grid).detach().numpy()[:,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d21f8f6",
   "metadata": {},
   "source": [
    "# old crap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cbfdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x : x**3\n",
    "\n",
    "x_grid = torch.reshape(torch.linspace(-1,1,50),[50,1])\n",
    "\n",
    "plt.plot(x_grid,x_grid)\n",
    "plt.plot(x_grid,f(x_grid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac4469",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_nn = Approximator().to(device)\n",
    "\n",
    "f_nn.nlatent = 20\n",
    "f_nn.ndim = 2\n",
    "\n",
    "f_nn.f0 = lambda x : x**5\n",
    "\n",
    "f_nn.r_n_repeats(100)\n",
    "\n",
    "print('discretisation info : ')\n",
    "print('\\nn repeats : %i' % f_nn.n_repeats, \n",
    "      '\\nh         : %4f' % f_nn.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7573a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('training f_nn: \\n')\n",
    "\n",
    "train_func_approx(f_nn,f,\n",
    "                  range_lr = [-1.,1.],\n",
    "                  MAX_EPOCH = 10,\n",
    "                  LR = 1e-3, \n",
    "                  gamma = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a7749",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_grid,f(xx_grid)[:,0], c = 'black')\n",
    "plt.plot(x_grid,f_nn(xx_grid).detach().numpy()[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c8dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = lambda x : f_nn.regressor(x) + x\n",
    "\n",
    "xx_grid = torch.cat([x_grid for _ in range(f_nn.ndim)],1)\n",
    "\n",
    "x = xx_grid\n",
    "\n",
    "fig,ax = plt.subplots(3,1,figsize = (20,20))\n",
    "\n",
    "\n",
    "ax[0].plot(x_grid,f(xx_grid)[:,0], c = 'black')\n",
    "\n",
    "\n",
    "for i in range(f_nn.ndim):\n",
    "\n",
    "    ax[0].plot(x_grid,f_nn(xx_grid).detach().numpy()[:,0])\n",
    "\n",
    "    ax[0].plot(x_grid,f_nn.regressor(xx_grid).detach().numpy()[:,0])\n",
    "\n",
    "\n",
    "ax[1].plot(x_grid,f(xx_grid)[:,0], c = 'black')\n",
    "\n",
    "for _ in range(f_nn.n_repeats):\n",
    "    \n",
    "    flux = f_nn.regressor(x)\n",
    "    \n",
    "    x = flux + x\n",
    "    \n",
    "    ax[1].plot(x_grid, x.detach().numpy()[:,0])\n",
    "\n",
    "    ax[2].plot(x_grid, flux.detach().numpy()[:,0])\n",
    "\n",
    "\n",
    "plt.show(fig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7acccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_grid,f(xx_grid)[:,0], c = 'black')\n",
    "plt.plot(x_grid,f_nn(xx_grid).detach().numpy()[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_grid,f(xx_grid)[:,0], c = 'black')\n",
    "plt.plot(x_grid,f_nn(xx_grid).detach().numpy()[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.ones_like(xx_grid[0])*0.5\n",
    "\n",
    "y = x0\n",
    "\n",
    "Y = [x0]\n",
    "\n",
    "for _ in range(f_nn.n_repeats):\n",
    "    \n",
    "    Y.append(y + f_nn.h*f_nn.regressor(y))\n",
    "    \n",
    "    y = Y[-1]\n",
    "    \n",
    "print(y, f_nn(x0))\n",
    "\n",
    "Z = [y]\n",
    "\n",
    "z = y\n",
    "\n",
    "for _ in range(f_nn.n_repeats):\n",
    "    \n",
    "    y = Z[-1]\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        z = y - f_nn.h*f_nn.regressor(z)\n",
    "\n",
    "    Z.append(z)\n",
    "    \n",
    "Y.reverse() \n",
    "    \n",
    "print(torch.cat((torch.stack(Y),torch.stack(Z)),axis = 1 ).detach())\n",
    "\n",
    "print('\\n initial error : %20f' % torch.norm(z-x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11b83a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def res_inverse(y,flux, n = 2, it = 5):\n",
    "\n",
    "    h = 1/n\n",
    "    \n",
    "    z = [y for _ in range(n+1)]\n",
    "    \n",
    "    for _ in range(it):\n",
    "    \n",
    "        for i in reversed(range(n)):\n",
    "\n",
    "            z[i] = z[i+1] - h*flux(z[i])\n",
    "             \n",
    "    return z[0]\n",
    "\n",
    "recon = res_inverse(f_nn(xx_grid),f_nn.regressor, n = f_nn.n_repeats, it = 5)\n",
    "recon = recon.detach()\n",
    "\n",
    "fig,ax = plt.subplots(f_nn.ndim + 1,1,figsize = (20,20))\n",
    "\n",
    "for i in range(f_nn.ndim):\n",
    "\n",
    "    ax[i].plot(x_grid,x_grid)\n",
    "\n",
    "    ax[i].plot(x_grid,recon[:,i])\n",
    "    \n",
    "error = torch.norm( xx_grid - recon, dim = 1).detach()\n",
    "\n",
    "ax[-1].plot(error )\n",
    "\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf3daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
